{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VEbgktUdDuyW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import cv2\n",
        "import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import random\n",
        "\n",
        "pose_csv = pd.read_csv('open/hand_gesture_pose.csv').values\n",
        "\n",
        "pose_info = {row[0] : row[1:] for row in pose_csv}\n",
        "pose_idx = {}\n",
        "pose_list = {}\n",
        "for i, pose_index in enumerate(pose_info.keys()):\n",
        "    pose_idx[pose_index] = i\n",
        "    pose_list[i] = pose_index\n",
        "\n",
        "pose_num = len(pose_info)\n",
        "\n",
        "testdata = []\n",
        "answer = pd.read_csv('open/answer.csv').values\n",
        "testpose = {row[0]:row[1] for row in answer}\n",
        "testlist = os.listdir('resized_test')\n",
        "output = {}\n",
        "test_transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "for fname in tqdm.tqdm(testlist):\n",
        "    imglist = os.listdir('resized_test/'+fname)\n",
        "    pose = pose_idx[testpose[int(fname)]]\n",
        "    for imgname in imglist:\n",
        "        imgdata = np.load('resized_test/'+str(fname)+\"/\"+str(imgname))\n",
        "        testdata.append([imgdata, fname, pose])\n",
        "    output[fname] = []\n",
        "\n",
        "\n",
        "class Hand_Dataset(Dataset):\n",
        "    def __init__(self, data,istrain, transform=None):\n",
        "        self.data = data\n",
        "        self.transform = transform\n",
        "        self.istrain = istrain\n",
        "        self.do = 0\n",
        "        \n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "      img_data, fname, label = self.data[index]\n",
        "      self.do += 1\n",
        "      if self.istrain:\n",
        "        rec_num = min(10, self.do//50000)\n",
        "        for _ in range(rec_num):\n",
        "            x = random.randrange(60,180)\n",
        "            y = random.randrange(60,180)\n",
        "            color = [random.randrange(0,255),random.randrange(0,255),random.randrange(0,255)]\n",
        "            img_data[x:x+10,y:y+10] = color\n",
        "          \n",
        "      if self.transform is not None:\n",
        "        img_data = self.transform(img_data)\n",
        "      return img_data, fname, label\n",
        "\n",
        "test_dataset = Hand_Dataset(testdata, False, test_transform)\n",
        "\n",
        "batch_size = 64\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset,batch_size=batch_size)\n",
        "\n",
        "\n",
        "\n",
        "name = 'vanila_cnn'\n",
        "result = {}\n",
        "resnet18 = models.resnet18(False)\n",
        "num_features = resnet18.fc.in_features\n",
        "\n",
        "resnet18.fc = nn.Linear(num_features, pose_num)\n",
        "\n",
        "resnet18.load_state_dict(torch.load(name+'.pt'))\n",
        "\n",
        "for i, data in enumerate(tqdm.tqdm(test_loader)):\n",
        "  resnet18.train(False)\n",
        "  resnet18.eval()\n",
        "  inputs, fnames, labels = data\n",
        "  \n",
        "  outputs = resnet18(inputs)\n",
        "\n",
        "  _, preds = torch.max(outputs.data, 1)\n",
        "  for fname, pred in zip(fnames, preds):\n",
        "    output[fname].append(pred)\n",
        "\n",
        "for fname in testlist:\n",
        "  result[fname] = pose_list[np.argmax(np.bincount(np.array(output[fname])))]\n",
        "\n",
        "sample = pd.read_csv('open/sample_submission.csv').values\n",
        "col = pd.read_csv('open/sample_submission.csv').columns\n",
        "\n",
        "col_dict = {}\n",
        "row_dict = {}\n",
        "\n",
        "for i, cname in enumerate(col):\n",
        "  if i==0:\n",
        "    continue\n",
        "  col_dict[int(cname[6:])] = i\n",
        "\n",
        "for i, row in enumerate(sample):\n",
        "  row_dict[row[0][-3:]] = i\n",
        "\n",
        "for fname in testlist:\n",
        "  output = result[fname]\n",
        "  sample[row_dict[fname]][col_dict[output]] = 1\n",
        "\n",
        "final = pd.DataFrame(sample,columns=col)\n",
        "final.to_csv(name+'.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AXqeiYX_D67X"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "VanillaCNN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}